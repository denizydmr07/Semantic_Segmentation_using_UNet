{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Drn0f_yvjjIQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nq929UTwj5BY"
      },
      "outputs": [],
      "source": [
        "# downloading the dataset and get info\n",
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqYOAGmUkC3_",
        "outputId": "7568affc-477c-4bd5-b70d-1b332314a194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['train', 'test'])\n"
          ]
        }
      ],
      "source": [
        "print(dataset.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PwWvCFNRknkW"
      },
      "outputs": [],
      "source": [
        "# preprocessing functions\n",
        "def random_flip(image, mask):\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    mask = tf.image.flip_left_right(mask)\n",
        "\n",
        "  return image, mask\n",
        "\n",
        "def normalize(image, mask):\n",
        "  image = tf.cast(image, tf.float32) / 255.\n",
        "  mask -= 1\n",
        "  return image, mask\n",
        "\n",
        "def preprocess_train(data):\n",
        "  \"\"\"\n",
        "  resizing, normalizing, and flipping the train data\n",
        "  \"\"\"\n",
        "  image = tf.image.resize(data[\"image\"], (128, 128), method=\"nearest\")\n",
        "  mask = tf.image.resize(data[\"segmentation_mask\"], (128, 128), method=\"nearest\")\n",
        "\n",
        "  image, mask = random_flip(image, mask)\n",
        "  image, mask = normalize(image, mask)\n",
        "\n",
        "  return image, mask\n",
        "\n",
        "def preprocess_test(data):\n",
        "  \"\"\"\n",
        "  resizing, and normalizing test data\n",
        "  \"\"\"\n",
        "  image = tf.image.resize(data[\"image\"], (128, 128), method=\"nearest\")\n",
        "  mask = tf.image.resize(data[\"segmentation_mask\"], (128, 128), method=\"nearest\")\n",
        "\n",
        "  image, mask = normalize(image, mask)\n",
        "\n",
        "  return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yGugK5CekpcX"
      },
      "outputs": [],
      "source": [
        "# preprocessing train and test\n",
        "train_dataset = dataset[\"train\"].map(preprocess_train,\n",
        "                                     num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = dataset[\"test\"].map(preprocess_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yTwJTop3ns30"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1024\n",
        "\n",
        "# shuffling and grouping the train set\n",
        "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "# prefetching to optimize preprocessing\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# grouping the test set\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ATD5xXMYo2h8"
      },
      "outputs": [],
      "source": [
        "# DEFINING THE UNET MODEL\n",
        "\n",
        "# Encoder utilities\n",
        "class Conv2D_Block(tf.keras.Model):\n",
        "  def __init__(self, filters, kernel_size = 3):\n",
        "    super(Conv2D_Block, self).__init__()\n",
        "    self.conv2d_1 = tf.keras.layers.Conv2D(filters, kernel_size,\n",
        "                                           kernel_initializer=\"he_normal\",\n",
        "                                           padding = \"same\",\n",
        "                                           activation = \"relu\")\n",
        "    self.conv2d_2 = tf.keras.layers.Conv2D(filters, kernel_size,\n",
        "                                           kernel_initializer=\"he_normal\",\n",
        "                                           padding = \"same\",\n",
        "                                           activation=\"relu\")\n",
        "\n",
        "  def call(self, input):\n",
        "    x = self.conv2d_1(input)\n",
        "    x = self.conv2d_2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Encoder_Block(tf.keras.Model):\n",
        "  def __init__(self, filters, kernel_size=3, pool_size=(2,2), dropout_rate=0.3):\n",
        "    super(Encoder_Block, self).__init__()\n",
        "    self.conv2d_block = Conv2D_Block(filters, kernel_size)\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size = 2)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, input):\n",
        "    \"\"\"\n",
        "    f - the output features of the convolution block\n",
        "    p - the maxpooled features with dropout\n",
        "    \"\"\"\n",
        "    f = self.conv2d_block(input)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "\n",
        "    return f, p\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.encoder_block_1 = Encoder_Block(filters = 64)\n",
        "    self.encoder_block_2 = Encoder_Block(filters = 128)\n",
        "    self.encoder_block_3 = Encoder_Block(filters = 256)\n",
        "    self.encoder_block_4 = Encoder_Block(filters = 512)\n",
        "\n",
        "  def call(self, input):\n",
        "    \"\"\"\n",
        "    p4 - the output maxpooled features of the last encoder block\n",
        "    (f1, f2, f3, f4) - the output features of all the encoder blocks\n",
        "    \"\"\"\n",
        "    f1, p1 = self.encoder_block_1(input)\n",
        "    f2, p2 = self.encoder_block_2(p1)\n",
        "    f3, p3 = self.encoder_block_3(p2)\n",
        "    f4, p4 = self.encoder_block_4(p3)\n",
        "\n",
        "    return p4, (f1,f2,f3,f4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EgTFQchJtfaI"
      },
      "outputs": [],
      "source": [
        "# Bottleneck utilities\n",
        "class Bottleneck(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Bottleneck, self).__init__()\n",
        "\n",
        "    self.conv2d_block = Conv2D_Block(filters=1024)\n",
        "\n",
        "  def call(self, input):\n",
        "    bottle_neck = self.conv2d_block(input)\n",
        "\n",
        "    return bottle_neck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "To5U6xFouKQb"
      },
      "outputs": [],
      "source": [
        "# Decoder utilities\n",
        "class Decoder_Block(tf.keras.Model):\n",
        "  def __init__(self, filters=64, kernel_size=3, strides=3, dropout_rate=0.3):\n",
        "    super(Decoder_Block, self).__init__()\n",
        "    self.conv2d_tp = tf.keras.layers.Conv2DTranspose(filters, kernel_size,\n",
        "                                                     strides=strides,\n",
        "                                                     padding=\"same\")\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.conv2d_block = Conv2D_Block(filters)\n",
        "\n",
        "  def call(self, input, conv_output):\n",
        "    u = self.conv2d_tp(input)\n",
        "    c = tf.keras.layers.concatenate([u, conv_output])\n",
        "    c = self.dropout(c)\n",
        "    c = self.conv2d_block(c)\n",
        "\n",
        "    return c\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self,output_channels):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "\n",
        "    self.decoder_block_1 = Decoder_Block(filters=512, kernel_size=3,\n",
        "                                         strides=2, dropout_rate=0.3)\n",
        "    self.decoder_block_2 = Decoder_Block(filters=256, kernel_size=3,\n",
        "                                      strides=2, dropout_rate=0.3)\n",
        "    self.decoder_block_3 = Decoder_Block(filters=128, kernel_size=3,\n",
        "                                  strides=2, dropout_rate=0.3)\n",
        "    self.decoder_block_4 = Decoder_Block(filters=64, kernel_size=3,\n",
        "                              strides=2, dropout_rate=0.3)\n",
        "    self.conv2d = tf.keras.layers.Conv2D(output_channels, (1,1),\n",
        "                                       activation=\"softmax\")\n",
        "\n",
        "  def call(self,inputs):\n",
        "    input, convs = inputs\n",
        "    f1, f2, f3, f4 = convs\n",
        "    c6 = self.decoder_block_1(input, f4)\n",
        "    c7 = self.decoder_block_2(c6, f3)\n",
        "    c8 = self.decoder_block_3(c7, f2)\n",
        "    c9 = self.decoder_block_4(c8, f1)\n",
        "\n",
        "    outputs = self.conv2d(c9)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wiWz3pGDyPo9"
      },
      "outputs": [],
      "source": [
        "# Defining UNet\n",
        "OUTPUT_CHANNELS = 3\n",
        "def UNet():\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=(128,128,3,))\n",
        "\n",
        "  encoder_out, convs = Encoder()(inputs)\n",
        "\n",
        "  bottleneck_out = Bottleneck()(encoder_out)\n",
        "\n",
        "  outputs = Decoder(output_channels=OUTPUT_CHANNELS)([bottleneck_out, convs])\n",
        "\n",
        "  unet = tf.keras.Model(inputs=inputs, outputs = outputs)\n",
        "\n",
        "  return unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EsR_Qt5Gzrbz"
      },
      "outputs": [],
      "source": [
        "unet = UNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW6IC4O6zs58",
        "outputId": "10f9a453-f6e5-4db3-9314-e7594af04c0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " encoder (Encoder)              ((None, 8, 8, 512),  4685376     ['input_1[0][0]']                \n",
            "                                 ((None, 128, 128,                                                \n",
            "                                64),                                                              \n",
            "                                 (None, 64, 64, 128                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 32, 32, 256                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 16, 16, 512                                               \n",
            "                                )))                                                               \n",
            "                                                                                                  \n",
            " bottleneck (Bottleneck)        (None, 8, 8, 1024)   14157824    ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Decoder)              (None, 128, 128, 3)  15670275    ['bottleneck[0][0]',             \n",
            "                                                                  'encoder[0][1]',                \n",
            "                                                                  'encoder[0][2]',                \n",
            "                                                                  'encoder[0][3]',                \n",
            "                                                                  'encoder[0][4]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34,513,475\n",
            "Trainable params: 34,513,475\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "unet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oTLKMg690eUy"
      },
      "outputs": [],
      "source": [
        "# compiling and training\n",
        "unet.compile(optimizer = tf.keras.optimizers.legacy.Adam(),\n",
        "             loss = \"sparse_categorical_crossentropy\",\n",
        "             metrics = [\"accuracy\"])\n",
        "\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"best_val.h5\",\n",
        "    monitor = \"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM0Hbkr_0_n6",
        "outputId": "989d0404-225d-4108-cfc5-3982ee9218a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 38s 404ms/step - loss: 0.9776 - accuracy: 0.5861 - val_loss: 0.7770 - val_accuracy: 0.7047\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 23s 354ms/step - loss: 0.7183 - accuracy: 0.7165 - val_loss: 0.6837 - val_accuracy: 0.7198\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 22s 394ms/step - loss: 0.6530 - accuracy: 0.7357 - val_loss: 0.6206 - val_accuracy: 0.7502\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 20s 346ms/step - loss: 0.6032 - accuracy: 0.7597 - val_loss: 0.5496 - val_accuracy: 0.7815\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 23s 410ms/step - loss: 0.5522 - accuracy: 0.7825 - val_loss: 0.5194 - val_accuracy: 0.7955\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 22s 393ms/step - loss: 0.5083 - accuracy: 0.8020 - val_loss: 0.4924 - val_accuracy: 0.8105\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 21s 373ms/step - loss: 0.4807 - accuracy: 0.8129 - val_loss: 0.4923 - val_accuracy: 0.8077\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 21s 369ms/step - loss: 0.4704 - accuracy: 0.8183 - val_loss: 0.4553 - val_accuracy: 0.8214\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 20s 346ms/step - loss: 0.4354 - accuracy: 0.8326 - val_loss: 0.4348 - val_accuracy: 0.8343\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 24s 432ms/step - loss: 0.4126 - accuracy: 0.8405 - val_loss: 0.3997 - val_accuracy: 0.8467\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 24s 428ms/step - loss: 0.3937 - accuracy: 0.8490 - val_loss: 0.3805 - val_accuracy: 0.8550\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 19s 327ms/step - loss: 0.3817 - accuracy: 0.8536 - val_loss: 0.3762 - val_accuracy: 0.8548\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 24s 424ms/step - loss: 0.3607 - accuracy: 0.8610 - val_loss: 0.3538 - val_accuracy: 0.8644\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 19s 329ms/step - loss: 0.3474 - accuracy: 0.8663 - val_loss: 0.3709 - val_accuracy: 0.8600\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 29s 511ms/step - loss: 0.3417 - accuracy: 0.8684 - val_loss: 0.3364 - val_accuracy: 0.8717\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 20s 349ms/step - loss: 0.3330 - accuracy: 0.8727 - val_loss: 0.3446 - val_accuracy: 0.8702\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 19s 327ms/step - loss: 0.3123 - accuracy: 0.8791 - val_loss: 0.3430 - val_accuracy: 0.8684\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 21s 373ms/step - loss: 0.3129 - accuracy: 0.8793 - val_loss: 0.3426 - val_accuracy: 0.8694\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 19s 326ms/step - loss: 0.2984 - accuracy: 0.8844 - val_loss: 0.3457 - val_accuracy: 0.8714\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 21s 374ms/step - loss: 0.2842 - accuracy: 0.8897 - val_loss: 0.3813 - val_accuracy: 0.8619\n"
          ]
        }
      ],
      "source": [
        "TRAIN_LENGTH = info.splits[\"train\"].num_examples\n",
        "EPOCHS = 20\n",
        "VAL_SUBSPLITS = 5\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "VALIDATION_STEPS = info.splits[\"test\"].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "history = unet.fit(train_dataset,\n",
        "                   epochs=EPOCHS,\n",
        "                   steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                   validation_data=test_dataset,\n",
        "                   validation_steps=VALIDATION_STEPS,\n",
        "                   callbacks = [callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zXR-2E6c1ppd"
      },
      "outputs": [],
      "source": [
        "def get_test_image_and_annotation_arrays():\n",
        "  ds = test_dataset.unbatch()\n",
        "  ds = ds.batch(info.splits['test'].num_examples)\n",
        "\n",
        "  images = []\n",
        "  y_true_segments = []\n",
        "\n",
        "  for image, annotation in ds.take(1):\n",
        "    y_true_segments = annotation.numpy()\n",
        "    images = image.numpy()\n",
        "\n",
        "  y_true_segments = y_true_segments[:(info.splits['test'].num_examples - (info.splits['test'].num_examples % BATCH_SIZE))]\n",
        "\n",
        "  return images[:(info.splits['test'].num_examples - (info.splits['test'].num_examples % BATCH_SIZE))], y_true_segments\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0].numpy()\n",
        "\n",
        "\n",
        "def make_predictions(image, mask, num=1):\n",
        "\n",
        "  image = np.reshape(image,(num, image.shape[0], image.shape[1], image.shape[2]))\n",
        "  pred_mask = unet.predict(image)\n",
        "  pred_mask = create_mask(pred_mask)\n",
        "\n",
        "  return pred_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0J6D7va__eAW"
      },
      "outputs": [],
      "source": [
        "def class_wise_metrics(y_true, y_pred):\n",
        "  class_wise_iou = []\n",
        "  class_wise_dice_score = []\n",
        "\n",
        "  smoothening_factor = 0.00001\n",
        "  for i in range(3):\n",
        "\n",
        "    intersection = np.sum((y_pred == i) * (y_true == i))\n",
        "    y_true_area = np.sum((y_true == i))\n",
        "    y_pred_area = np.sum((y_pred == i))\n",
        "    combined_area = y_true_area + y_pred_area\n",
        "\n",
        "    iou = (intersection + smoothening_factor) / (combined_area - intersection + smoothening_factor)\n",
        "    class_wise_iou.append(iou)\n",
        "\n",
        "    dice_score =  2 * ((intersection + smoothening_factor) / (combined_area + smoothening_factor))\n",
        "    class_wise_dice_score.append(dice_score)\n",
        "\n",
        "  return class_wise_iou, class_wise_dice_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aau18-Dt_jzN",
        "outputId": "2a1a9073-1676-4eef-a8be-c78fd55a302e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 17s 301ms/step\n"
          ]
        }
      ],
      "source": [
        "# get the ground truth from the test set\n",
        "y_true_images, y_true_segments = get_test_image_and_annotation_arrays()\n",
        "\n",
        "# feed the test set to th emodel to get the predicted masks\n",
        "results = unet.predict(test_dataset, steps=info.splits['test'].num_examples//BATCH_SIZE)\n",
        "results = np.argmax(results, axis=3)\n",
        "results = results[..., tf.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0_zeb4vt_q5v"
      },
      "outputs": [],
      "source": [
        "# compute the class wise metrics\n",
        "cls_wise_iou, cls_wise_dice_score = class_wise_metrics(y_true_segments, results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "endr_Q1cSZcv",
        "outputId": "242a790c-6e4e-4cef-f487-bfcc4071abd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pet         0.7390193584173999 \n",
            "background  0.849992509611345 \n",
            "outline     0.3968899396172031 \n"
          ]
        }
      ],
      "source": [
        "# class list of the mask pixels\n",
        "class_names = ['pet', 'background', 'outline']\n",
        "# show the IOU for each class\n",
        "for idx, iou in enumerate(cls_wise_iou):\n",
        "  spaces = ' ' * (10-len(class_names[idx]) + 2)\n",
        "  print(\"{}{}{} \".format(class_names[idx], spaces, iou))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4lrtmz3SaH6",
        "outputId": "5860859c-f150-4dd8-f6bb-1a8e80852fdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pet         0.8499265460622979 \n",
            "background  0.918914541756756 \n",
            "outline     0.5682479748208263 \n"
          ]
        }
      ],
      "source": [
        "# show the Dice Score for each class\n",
        "for idx, dice_score in enumerate(cls_wise_dice_score):\n",
        "  spaces = ' ' * (10-len(class_names[idx]) + 2)\n",
        "  print(\"{}{}{} \".format(class_names[idx], spaces, dice_score))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
